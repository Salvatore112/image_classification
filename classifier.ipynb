{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pasha/image_classification/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/pasha/.cache/kagglehub/datasets/sumn2u/garbage-classification-v2/versions/8\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"sumn2u/garbage-classification-v2\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trash', 'glass', 'battery', 'clothes', 'metal', 'plastic', 'cardboard', 'paper', 'biological', 'shoes']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import glob\n",
    "\n",
    "from scipy.stats import mannwhitneyu, spearmanr, kruskal\n",
    "from scipy.stats import ttest_ind, pearsonr, chi2_contingency\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import f_oneway\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# Suppress warnings for better output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "classes = os.listdir(os.path.join(path, \"garbage-dataset\"))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yellow_amount(image):\n",
    "    \"\"\"Calculate the amount of yellow color in the image.\"\"\"\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_yellow = np.array([20, 100, 100])\n",
    "    upper_yellow = np.array([30, 255, 255])\n",
    "    yellow_mask = cv2.inRange(hsv_image, lower_yellow, upper_yellow)\n",
    "    yellow_amount = cv2.countNonZero(yellow_mask)\n",
    "    return yellow_amount\n",
    "\n",
    "def calculate_silver_amount(image):\n",
    "    \"\"\"Calculate the amount of silver color in the image.\"\"\"\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_silver = np.array([0, 0, 200])\n",
    "    upper_silver = np.array([180, 25, 255])\n",
    "    silver_mask = cv2.inRange(hsv_image, lower_silver, upper_silver)\n",
    "    silver_amount = cv2.countNonZero(silver_mask)\n",
    "    return silver_amount\n",
    "\n",
    "def calculate_parallel_lines(image):\n",
    "    \"\"\"Calculate the amount of parallel lines in the image.\"\"\"\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray_image, 50, 150, apertureSize=3)\n",
    "    \n",
    "    # Detect lines using Hough Transform\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, threshold=100)\n",
    "    \n",
    "    if lines is not None:\n",
    "        return len(lines)  # Return the number of detected lines\n",
    "    return 0  # No lines detected\n",
    "\n",
    "def detect_cylinders(image):\n",
    "    \"\"\"Detect cylindrical shapes in the image.\"\"\"\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (9, 9), 2)\n",
    "\n",
    "    # Detect circles using Hough Transform\n",
    "    circles = cv2.HoughCircles(blurred_image, cv2.HOUGH_GRADIENT, dp=1, minDist=30,\n",
    "                               param1=100, param2=30, minRadius=10, maxRadius=100)\n",
    "\n",
    "    if circles is not None:\n",
    "        return circles.shape[1]  # Return the number of detected circles\n",
    "    return 0  # No circles detected\n",
    "\n",
    "def calculate_reflection(image):\n",
    "    \"\"\"Calculate the amount of bright areas in the image to detect reflections.\"\"\"\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Threshold to find bright areas\n",
    "    _, bright_mask = cv2.threshold(gray_image, 200, 255, cv2.THRESH_BINARY)\n",
    "    reflection_amount = cv2.countNonZero(bright_mask)\n",
    "    return reflection_amount\n",
    "\n",
    "def calculate_transparency(image):\n",
    "    \"\"\"\n",
    "    Calculate the amount of transparent areas in the image.\n",
    "    Transparent areas are identified as regions with low saturation and brightness in the HSV color space.\n",
    "    \"\"\"\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # Define thresholds for low saturation and brightness (transparent regions)\n",
    "    lower_transparent = np.array([0, 0, 0])\n",
    "    upper_transparent = np.array([180, 50, 50])  # Adjust upper threshold as needed\n",
    "    transparent_mask = cv2.inRange(hsv_image, lower_transparent, upper_transparent)\n",
    "    transparency_amount = cv2.countNonZero(transparent_mask)\n",
    "    return transparency_amount\n",
    "\n",
    "def calculate_texture_smoothness(image):\n",
    "    \"\"\"Calculate the smoothness of the texture in the image.\"\"\"\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    glcm = graycomatrix(gray_image, [1], [0], 256, symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    return contrast\n",
    "\n",
    "def calculate_shininess(image):\n",
    "    \"\"\"Calculate the shininess of the image based on bright pixels.\"\"\"\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    bright_pixels = np.sum(gray_image > 220)  # Count pixels with intensity greater than 220\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    shininess = bright_pixels / total_pixels  # Proportion of bright pixels\n",
    "    return shininess\n",
    "\n",
    "def calculate_surface_anisotropy(image):\n",
    "    \"\"\"\n",
    "    Calculate the anisotropy of the surface using Gabor filters.\n",
    "    Measures how directional the texture is.\n",
    "    \"\"\"\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Parameters for Gabor filter\n",
    "    num_orientations = 8  # Number of orientations to test\n",
    "    kernel_size = 21      # Size of the Gabor filter kernel\n",
    "    sigma = 5.0           # Standard deviation of the Gaussian function\n",
    "    lambd = 10.0          # Wavelength of the sinusoidal component\n",
    "    gamma = 0.5           # Spatial aspect ratio\n",
    "    \n",
    "    responses = []\n",
    "    \n",
    "    # Apply Gabor filters with different orientations\n",
    "    for theta in np.linspace(0, np.pi, num_orientations, endpoint=False):\n",
    "        gabor_kernel = cv2.getGaborKernel((kernel_size, kernel_size), sigma, theta, lambd, gamma, 0, ktype=cv2.CV_32F)\n",
    "        filtered_image = cv2.filter2D(gray_image, cv2.CV_32F, gabor_kernel)\n",
    "        responses.append(np.mean(filtered_image ** 2))  # Energy of the response\n",
    "\n",
    "    # Measure anisotropy: ratio of maximum response to mean response\n",
    "    max_response = max(responses)\n",
    "    mean_response = np.mean(responses)\n",
    "    anisotropy = max_response / mean_response if mean_response > 0 else 0\n",
    "\n",
    "    return anisotropy\n",
    "\n",
    "def calculate_aspect_ratio(image):\n",
    "    \"\"\"\n",
    "    Calculate the average width-to-height ratio of detected objects in the image.\n",
    "    \"\"\"\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_image = cv2.threshold(gray_image, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(contours) == 0:\n",
    "        return 0  # No objects found\n",
    "\n",
    "    aspect_ratios = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if h > 0:  # Avoid division by zero\n",
    "            aspect_ratios.append(w / h)\n",
    "\n",
    "    if len(aspect_ratios) == 0:\n",
    "        return 0\n",
    "\n",
    "    # Return the average aspect ratio\n",
    "    return sum(aspect_ratios) / len(aspect_ratios)\n",
    "\n",
    "def calculate_whiteness(image):\n",
    "    \"\"\"Calculate the proportion of white pixels in the image.\"\"\"\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_white = np.array([0, 0, 200])\n",
    "    upper_white = np.array([180, 50, 255])\n",
    "    white_mask = cv2.inRange(hsv_image, lower_white, upper_white)\n",
    "    whiteness = cv2.countNonZero(white_mask) / (image.shape[0] * image.shape[1])\n",
    "    return whiteness\n",
    "\n",
    "def calculate_line_curvature(image):\n",
    "    \"\"\"\n",
    "    Calculate the average curvature of detected edges in the image.\n",
    "    High curvature may indicate folds or wavy edges, common in clothing.\n",
    "    \"\"\"\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray_image, 50, 150, apertureSize=3)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return 0  # No contours found\n",
    "\n",
    "    curvatures = []\n",
    "    for contour in contours:\n",
    "        if len(contour) >= 5:  # Need at least 5 points to fit an ellipse\n",
    "            ellipse = cv2.fitEllipse(contour)\n",
    "            major_axis = max(ellipse[1])  # Length of the major axis\n",
    "            minor_axis = min(ellipse[1])  # Length of the minor axis\n",
    "            \n",
    "            if major_axis > 0:\n",
    "                curvature = minor_axis / major_axis  # Ratio of axes approximates curvature\n",
    "                curvatures.append(curvature)\n",
    "    \n",
    "    if len(curvatures) == 0:\n",
    "        return 0\n",
    "\n",
    "    # Return the average curvature\n",
    "    return sum(curvatures) / len(curvatures)\n",
    "\n",
    "def get_features(image):\n",
    "    \"\"\"\n",
    "    Get a set of features (yellow amount, silver amount, parallel lines, cylindrical shapes, \n",
    "    reflections, transparency, texture smoothness, shininess, surface anisotropy, aspect ratio,\n",
    "    whiteness, edge smoothness).\n",
    "    \"\"\"\n",
    "    yellow_amount = calculate_yellow_amount(image)\n",
    "    silver_amount = calculate_silver_amount(image)\n",
    "    parallel_lines = calculate_parallel_lines(image)\n",
    "    cylinder_count = detect_cylinders(image)\n",
    "    reflection_amount = calculate_reflection(image)\n",
    "    transparency_amount = calculate_transparency(image)\n",
    "    texture_smoothness = calculate_texture_smoothness(image)\n",
    "    shininess = calculate_shininess(image)\n",
    "    surface_anisotropy = calculate_surface_anisotropy(image)\n",
    "    aspect_ratio = calculate_aspect_ratio(image)\n",
    "    whiteness = calculate_whiteness(image)\n",
    "    line_curvature = calculate_line_curvature(image)\n",
    "    return (yellow_amount, silver_amount, parallel_lines, cylinder_count, reflection_amount,\n",
    "            transparency_amount, texture_smoothness, shininess, surface_anisotropy, \n",
    "            aspect_ratio, whiteness, line_curvature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surface Anisotropy: (15834, 284114, 140, 15, 303454, 0, np.float64(150.46217028380636), np.float64(0.8047277777777778), np.float32(2.768033), 1.0, 0.7999305555555556, 0.39463143158270836)\n"
     ]
    }
   ],
   "source": [
    "# Example usage with an image\n",
    "test_im = cv2.imread(path + \"/garbage-dataset/cardboard/cardboard_25.jpg\")\n",
    "anisotropy_feature = get_features(test_im)\n",
    "print(\"Surface Anisotropy:\", anisotropy_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6325110689437066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     battery       0.67      0.60      0.64       145\n",
      "  biological       0.57      0.72      0.64       138\n",
      "   cardboard       0.73      0.60      0.66       311\n",
      "     clothes       0.72      0.96      0.82       886\n",
      "       glass       0.51      0.57      0.54       455\n",
      "       metal       0.42      0.17      0.24       163\n",
      "       paper       0.63      0.50      0.56       263\n",
      "     plastic       0.60      0.43      0.50       327\n",
      "       shoes       0.51      0.45      0.48       317\n",
      "       trash       0.61      0.47      0.53       157\n",
      "\n",
      "    accuracy                           0.63      3162\n",
      "   macro avg       0.60      0.55      0.56      3162\n",
      "weighted avg       0.62      0.63      0.61      3162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to hold features and labels\n",
    "features = []\n",
    "labels = []\n",
    "test_images = []  # List to hold paths of test images\n",
    "\n",
    "# Loop through each class and extract features from images\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(path + \"/garbage-dataset/\", class_name)\n",
    "    image_names = os.listdir(class_path)\n",
    "\n",
    "    # Split the images into training and testing sets (80% train, 20% test)\n",
    "    train_images, test_images_class = train_test_split(image_names, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Process training images\n",
    "    for image_name in train_images:\n",
    "        image_path = os.path.join(class_path, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is not None:\n",
    "            features_list = get_features(image)\n",
    "            features.append(features_list)\n",
    "            labels.append(class_name)\n",
    "\n",
    "    # Collect test images for manual testing\n",
    "    for image_name in test_images_class:\n",
    "        test_images.append(os.path.join(class_path, image_name))\n",
    "\n",
    "# Convert features and labels to a DataFrame\n",
    "df = pd.DataFrame(features, columns=['yellow_amount', 'silver_amount', 'parallel_lines', 'cylinder_count', \n",
    "                                     'reflection_amount', 'transparency_amount', 'texture_smoothness', \n",
    "                                     'shininess', 'surface_anisotropy', 'aspect_ratio', \n",
    "                                     'whiteness', 'line_curvature'])\n",
    "df['label'] = labels\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df[['yellow_amount', 'silver_amount', 'parallel_lines', 'cylinder_count', \n",
    "        'reflection_amount', 'transparency_amount', 'texture_smoothness', \n",
    "        'shininess', 'surface_anisotropy', 'aspect_ratio', 'whiteness','line_curvature']]\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Function to classify a new image\n",
    "def classify_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is not None:\n",
    "        features_list = get_features(image)\n",
    "        feature = np.array([features_list])  # Convert to 2D array for prediction\n",
    "        prediction = classifier.predict(feature)\n",
    "        return prediction[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: glass\n"
     ]
    }
   ],
   "source": [
    "# Classifier testing (runs classifier for a specific image)\n",
    "result = classify_image(path + '/garbage-dataset/metal/metal_2370.jpg') \n",
    "print(\"Predicted class:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class counts for test images containing trash:\n",
      "Class: trash, Count: 87\n",
      "Class: clothes, Count: 11\n",
      "Class: plastic, Count: 12\n",
      "Class: glass, Count: 45\n",
      "Class: paper, Count: 4\n",
      "Class: shoes, Count: 9\n",
      "Class: metal, Count: 6\n",
      "Class: battery, Count: 3\n",
      "Class: cardboard, Count: 10\n",
      "Class: biological, Count: 3\n",
      "Predicted class counts for test images containing glass:\n",
      "Class: glass, Count: 365\n",
      "Class: metal, Count: 10\n",
      "Class: trash, Count: 15\n",
      "Class: plastic, Count: 37\n",
      "Class: shoes, Count: 54\n",
      "Class: clothes, Count: 75\n",
      "Class: biological, Count: 18\n",
      "Class: cardboard, Count: 8\n",
      "Class: paper, Count: 14\n",
      "Class: battery, Count: 17\n",
      "Predicted class counts for test images containing battery:\n",
      "Class: shoes, Count: 29\n",
      "Class: glass, Count: 23\n",
      "Class: battery, Count: 116\n",
      "Class: biological, Count: 11\n",
      "Class: trash, Count: 1\n",
      "Class: clothes, Count: 4\n",
      "Class: cardboard, Count: 3\n",
      "Class: plastic, Count: 1\n",
      "Class: metal, Count: 1\n",
      "Predicted class counts for test images containing clothes:\n",
      "Class: clothes, Count: 1006\n",
      "Class: paper, Count: 13\n",
      "Class: plastic, Count: 14\n",
      "Class: shoes, Count: 7\n",
      "Class: biological, Count: 7\n",
      "Class: cardboard, Count: 3\n",
      "Class: glass, Count: 14\n",
      "Class: metal, Count: 1\n",
      "Class: battery, Count: 1\n",
      "Predicted class counts for test images containing metal:\n",
      "Class: clothes, Count: 41\n",
      "Class: shoes, Count: 35\n",
      "Class: battery, Count: 5\n",
      "Class: metal, Count: 43\n",
      "Class: glass, Count: 35\n",
      "Class: paper, Count: 10\n",
      "Class: biological, Count: 13\n",
      "Class: plastic, Count: 12\n",
      "Class: cardboard, Count: 6\n",
      "Class: trash, Count: 4\n",
      "Predicted class counts for test images containing plastic:\n",
      "Class: plastic, Count: 171\n",
      "Class: glass, Count: 61\n",
      "Class: clothes, Count: 89\n",
      "Class: battery, Count: 2\n",
      "Class: paper, Count: 17\n",
      "Class: cardboard, Count: 18\n",
      "Class: metal, Count: 4\n",
      "Class: shoes, Count: 15\n",
      "Class: biological, Count: 7\n",
      "Class: trash, Count: 13\n",
      "Predicted class counts for test images containing cardboard:\n",
      "Class: cardboard, Count: 216\n",
      "Class: clothes, Count: 57\n",
      "Class: paper, Count: 13\n",
      "Class: glass, Count: 22\n",
      "Class: shoes, Count: 13\n",
      "Class: plastic, Count: 15\n",
      "Class: trash, Count: 9\n",
      "Class: biological, Count: 14\n",
      "Class: battery, Count: 4\n",
      "Class: metal, Count: 2\n",
      "Predicted class counts for test images containing paper:\n",
      "Class: cardboard, Count: 14\n",
      "Class: clothes, Count: 58\n",
      "Class: glass, Count: 33\n",
      "Class: metal, Count: 5\n",
      "Class: paper, Count: 183\n",
      "Class: plastic, Count: 22\n",
      "Class: shoes, Count: 9\n",
      "Class: battery, Count: 4\n",
      "Class: trash, Count: 6\n",
      "Class: biological, Count: 2\n",
      "Predicted class counts for test images containing biological:\n",
      "Class: biological, Count: 136\n",
      "Class: clothes, Count: 12\n",
      "Class: glass, Count: 16\n",
      "Class: shoes, Count: 27\n",
      "Class: trash, Count: 1\n",
      "Class: paper, Count: 2\n",
      "Class: cardboard, Count: 4\n",
      "Class: plastic, Count: 2\n",
      "Predicted class counts for test images containing shoes:\n",
      "Class: glass, Count: 54\n",
      "Class: shoes, Count: 201\n",
      "Class: clothes, Count: 73\n",
      "Class: battery, Count: 11\n",
      "Class: cardboard, Count: 13\n",
      "Class: plastic, Count: 8\n",
      "Class: trash, Count: 3\n",
      "Class: paper, Count: 6\n",
      "Class: metal, Count: 3\n",
      "Class: biological, Count: 24\n"
     ]
    }
   ],
   "source": [
    "# Classifier testing (runs classifier for the remaining images)\n",
    "def test_classify(test_images, target_class_name):\n",
    "    predictions = defaultdict(int)\n",
    "    for test_image in test_images:\n",
    "        if target_class_name in test_image:  \n",
    "            predicted_class = classify_image(test_image)  \n",
    "            predictions[predicted_class] += 1 \n",
    "    return dict(predictions)  \n",
    "\n",
    "for class_name in classes:\n",
    "    results = test_classify(test_images, class_name)\n",
    "    print(\"Predicted class counts for test images containing \" + class_name + ':')\n",
    "    for class_name, count in results.items():\n",
    "        print(f\"Class: {class_name}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гипотеза №1 О наличие картона на картинке можно судить по скосу желтого цвета.\n",
    "\n",
    "- Способы проверки\n",
    "    - **t-критерий Стьюдента (t-test)**: Сравнение средней доли жёлтого цвета в картинках с картоном и другими классами.\n",
    "    - **ANOVA (дисперсионный анализ)**: Проверка, есть ли значимые различия между группами (картон и другие классы) по количеству жёлтого цвета.\n",
    "    - **Критерий Манна-Уитни (U-тест)**: Непараметрический тест для сравнения распределений двух групп (в данном случае картон и другие классы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-test: Statistic = 3.683066343249196, p-value = 0.00023621963453461276\n",
      "ANOVA: Statistic = 16.865194578791744, p-value = 4.0292196417557166e-05\n",
      "Mann-Whitney: Statistic = 22080315.5, p-value = 1.0126318223771204e-146\n",
      "Гипотеза подтверждена: наличие картона связано c желтым цветом.\n"
     ]
    }
   ],
   "source": [
    "cardboard_path = os.path.join(path + \"/garbage-dataset\", \"cardboard\")\n",
    "other_paths = [os.path.join(path + \"/garbage-dataset\", cls) for cls in classes if cls != \"cardboard\"]\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        image = cv2.imread(filepath)\n",
    "        if image is not None: \n",
    "            images.append(image)\n",
    "    return images\n",
    "\n",
    "cardboard_images = load_images_from_folder(cardboard_path)\n",
    "cardboard_yellow_amounts = [calculate_yellow_amount(img) for img in cardboard_images]\n",
    "\n",
    "other_yellow_amounts = []\n",
    "for other_path in other_paths:\n",
    "    other_images = load_images_from_folder(other_path)\n",
    "    other_yellow_amounts.extend([calculate_yellow_amount(img) for img in other_images])\n",
    "\n",
    "# Проверка гипотез\n",
    "# 1. t-критерий Стьюдента\n",
    "t_stat, t_pvalue = ttest_ind(cardboard_yellow_amounts, other_yellow_amounts, equal_var=False)\n",
    "\n",
    "# 2. ANOVA\n",
    "anova_stat, anova_pvalue = f_oneway(cardboard_yellow_amounts, other_yellow_amounts)\n",
    "\n",
    "# 3. Критерий Манна-Уитни\n",
    "mann_stat, mann_pvalue = mannwhitneyu(cardboard_yellow_amounts, other_yellow_amounts, alternative='two-sided')\n",
    "\n",
    "results = {\n",
    "    \"t-test\": {\"statistic\": t_stat, \"p-value\": t_pvalue},\n",
    "    \"ANOVA\": {\"statistic\": anova_stat, \"p-value\": anova_pvalue},\n",
    "    \"Mann-Whitney\": {\"statistic\": mann_stat, \"p-value\": mann_pvalue},\n",
    "}\n",
    "\n",
    "for test, result in results.items():\n",
    "    print(f\"{test}: Statistic = {result['statistic']}, p-value = {result['p-value']}\")\n",
    "\n",
    "alpha = 0.05\n",
    "hypothesis_results = {test: result['p-value'] < alpha for test, result in results.items()}\n",
    "\n",
    "if all(hypothesis_results.values()):\n",
    "    print(\"Гипотеза подтверждена: наличие картона связано c желтым цветом.\")\n",
    "else:\n",
    "    print(\"Гипотеза не подтверждена: наличие картона не связано c желтым цветом.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гипотеза №2 О наличие металла на картинке можно судить по скосу серого (серебряного) цвета.\n",
    "\n",
    "- Способы проверки\n",
    "    - **t-критерий Стьюдента (t-test)**: Сравнение средней доли серебряного цвета в картинках с метеаллом и другими классами.\n",
    "    - **ANOVA (дисперсионный анализ)**: Проверка, есть ли значимые различия между группами (металл и другие классы) по количеству серебряного цвета.\n",
    "    - **Критерий Манна-Уитни (U-тест)**: Непараметрический тест для сравнения распределений двух групп (в данном случае металл и другие классы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-test: Statistic = -2.284424004913432, p-value = 0.022401779559765453\n",
      "ANOVA: Statistic = 0.5733189930562239, p-value = 0.448952071385762\n",
      "Mann-Whitney: Statistic = 10996543.5, p-value = 5.262970510833023e-16\n",
      "Гипотеза не подтверждена: наличие металла не связано c серебряным цветом.\n"
     ]
    }
   ],
   "source": [
    "metal_path = os.path.join(path + \"/garbage-dataset\", \"metal\")\n",
    "other_paths = [os.path.join(path + \"/garbage-dataset\", cls) for cls in classes if cls != \"metal\"]\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        image = cv2.imread(filepath)\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "    return images\n",
    "\n",
    "metal_images = load_images_from_folder(metal_path)\n",
    "metal_silver_amounts = [calculate_silver_amount(img) for img in metal_images]\n",
    "\n",
    "other_silver_amounts = []\n",
    "for other_path in other_paths:\n",
    "    other_images = load_images_from_folder(other_path)\n",
    "    other_silver_amounts.extend([calculate_silver_amount(img) for img in other_images])\n",
    "\n",
    "# Проверка гипотез\n",
    "# 1. t-критерий Стьюдента\n",
    "t_stat, t_pvalue = ttest_ind(metal_silver_amounts, other_silver_amounts, equal_var=False)\n",
    "\n",
    "# 2. ANOVA\n",
    "anova_stat, anova_pvalue = f_oneway(metal_silver_amounts, other_silver_amounts)\n",
    "\n",
    "# 3. Критерий Манна-Уитни\n",
    "mann_stat, mann_pvalue = mannwhitneyu(metal_silver_amounts, other_silver_amounts, alternative='two-sided')\n",
    "\n",
    "results = {\n",
    "    \"t-test\": {\"statistic\": t_stat, \"p-value\": t_pvalue},\n",
    "    \"ANOVA\": {\"statistic\": anova_stat, \"p-value\": anova_pvalue},\n",
    "    \"Mann-Whitney\": {\"statistic\": mann_stat, \"p-value\": mann_pvalue},\n",
    "}\n",
    "\n",
    "for test, result in results.items():\n",
    "    print(f\"{test}: Statistic = {result['statistic']}, p-value = {result['p-value']}\")\n",
    "\n",
    "alpha = 0.05\n",
    "hypothesis_results = {test: result['p-value'] < alpha for test, result in results.items()}\n",
    "\n",
    "if all(hypothesis_results.values()):\n",
    "    print(\"Гипотеза подтверждена: наличие металла связано c серебряным цветом.\")\n",
    "else:\n",
    "    print(\"Гипотеза не подтверждена: наличие металла не связано c серебряным цветом.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гипотеза №3 На картинках с картоном присутствует множество параллельных линий.\n",
    "\n",
    "- Способы проверки\n",
    "    - **t-критерий Стьюдента (t-test)**: Сравнение средней доли параллельных линий в картинках с картоном и другими классами.\n",
    "    - **ANOVA (дисперсионный анализ)**: Проверка, есть ли значимые различия между группами (картон и другие классы) по количеству параллельных линий.\n",
    "    - **Критерий хи-квадрат**: Проверка гипотезы об отличии доли изображений с высокими количествами параллельных линий между картоном и другими классами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-test: Statistic = -11.379057124078555, p-value = 1.9776123451846287e-29\n",
      "ANOVA: Statistic = 52.405427227996164, p-value = 4.680228101392663e-13\n",
      "Chi-square: Statistic = 19.34257889433447, p-value = 1.0924297310604447e-05\n",
      "Гипотеза подтверждена: изображения c картоном имеют больше параллельных линий.\n"
     ]
    }
   ],
   "source": [
    "cardboard_path = os.path.join(path + \"/garbage-dataset\", \"cardboard\")\n",
    "other_paths = [os.path.join(path + \"/garbage-dataset\", cls) for cls in classes if cls != \"cardboard\"]\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        image = cv2.imread(filepath)\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "    return images\n",
    "\n",
    "cardboard_images = load_images_from_folder(cardboard_path)\n",
    "cardboard_features = [calculate_parallel_lines(img) for img in cardboard_images]\n",
    "\n",
    "other_features = []\n",
    "for other_path in other_paths:\n",
    "    other_images = load_images_from_folder(other_path)\n",
    "    other_features.extend([calculate_parallel_lines(img) for img in other_images])\n",
    "\n",
    "# Проверка гипотез\n",
    "# 1. t-критерий Стьюдента\n",
    "t_stat, t_pvalue = ttest_ind(cardboard_features, other_features, equal_var=False)\n",
    "\n",
    "# 2. ANOVA\n",
    "anova_stat, anova_pvalue = f_oneway(cardboard_features, other_features)\n",
    "\n",
    "# 3. Критерий хи-квадрат\n",
    "threshold = np.percentile(cardboard_features, 75) \n",
    "cardboard_high = sum(x >= threshold for x in cardboard_features)\n",
    "cardboard_low = len(cardboard_features) - cardboard_high\n",
    "other_high = sum(x >= threshold for x in other_features)\n",
    "other_low = len(other_features) - other_high\n",
    "chi2_stat, chi2_pvalue, _, _ = chi2_contingency([[cardboard_high, cardboard_low], [other_high, other_low]])\n",
    "\n",
    "results = {\n",
    "    \"t-test\": {\"statistic\": t_stat, \"p-value\": t_pvalue},\n",
    "    \"ANOVA\": {\"statistic\": anova_stat, \"p-value\": anova_pvalue},\n",
    "    \"Chi-square\": {\"statistic\": chi2_stat, \"p-value\": chi2_pvalue},\n",
    "}\n",
    "\n",
    "for test, result in results.items():\n",
    "    print(f\"{test}: Statistic = {result['statistic']}, p-value = {result['p-value']}\")\n",
    "\n",
    "# Итоговая проверка гипотезы\n",
    "alpha = 0.05\n",
    "hypothesis_results = {test: result['p-value'] < alpha for test, result in results.items()}\n",
    "\n",
    "if all(hypothesis_results.values()):\n",
    "    print(\"Гипотеза подтверждена: изображения c картоном имеют больше параллельных линий.\")\n",
    "else:\n",
    "    print(\"Гипотеза не подтверждена: изображения c картоном не имеют значительно больше параллельных линий.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гипотеза №5 Металлические поверхности часто имеют высокую отражающую способность. \n",
    "\n",
    "- Способы проверки:\n",
    "    - **t-критерий Стьюдента (t-test):** Сравнение средней отражающей способности на изображениях металла и других классов.\n",
    "    - **Корреляция Пирсона:** Проверка линейной связи между количеством отражений и принадлежностью к классу \"металл\".\n",
    "    - **Критерий хи-квадрат:** Проверка отличий доли изображений с высоким уровнем отражений между металлом и другими классами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-test: Statistic = -2.5612454595984153, p-value = 0.010464870898548239\n",
      "Pearson Correlation: Statistic = 0.005891723334828736, p-value = 0.407558471373331\n",
      "Chi-square: Statistic = 35.91242941824723, p-value = 2.0638790312840235e-09\n",
      "Гипотеза не подтверждена: наличие металла не связано с высоким уровнем отражений.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metal_path = os.path.join(path + \"/garbage-dataset\", \"metal\")\n",
    "other_paths = [os.path.join(path + \"/garbage-dataset\", cls) for cls in classes if cls != \"metal\"]\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        image = cv2.imread(filepath)\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "    return images\n",
    "\n",
    "metal_images = load_images_from_folder(metal_path)\n",
    "metal_reflections = [calculate_reflection(img) for img in metal_images]\n",
    "\n",
    "other_reflections = []\n",
    "for other_path in other_paths:\n",
    "    other_images = load_images_from_folder(other_path)\n",
    "    other_reflections.extend([calculate_reflection(img) for img in other_images])\n",
    "\n",
    "# 1. t-критерий Стьюдента\n",
    "t_stat, t_pvalue = ttest_ind(metal_reflections, other_reflections, equal_var=False)\n",
    "\n",
    "# 2. Корреляция Пирсона\n",
    "le = LabelEncoder()\n",
    "all_reflections = metal_reflections + other_reflections\n",
    "all_labels = ['metal'] * len(metal_reflections) + ['other'] * len(other_reflections)\n",
    "numeric_labels = le.fit_transform(all_labels)\n",
    "\n",
    "correlation, p_value_corr = pearsonr(all_reflections, numeric_labels)\n",
    "\n",
    "# 3. Тест хи-квадрат\n",
    "reflection_binary = [1 if reflection >= 100 else 0 for reflection in all_reflections]\n",
    "contingency_table = pd.crosstab(reflection_binary, numeric_labels)\n",
    "chi2_stat, p_value_chi2, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "results = {\n",
    "    \"t-test\": {\"statistic\": t_stat, \"p-value\": t_pvalue},\n",
    "    \"Pearson Correlation\": {\"statistic\": correlation, \"p-value\": p_value_corr},\n",
    "    \"Chi-square\": {\"statistic\": chi2_stat, \"p-value\": p_value_chi2},\n",
    "}\n",
    "\n",
    "for test, result in results.items():\n",
    "    print(f\"{test}: Statistic = {result['statistic']}, p-value = {result['p-value']}\")\n",
    "\n",
    "alpha = 0.05\n",
    "hypothesis_results = {test: result['p-value'] < alpha for test, result in results.items()}\n",
    "\n",
    "if all(hypothesis_results.values()):\n",
    "    print(\"Гипотеза подтверждена: наличие металла связано с высоким уровнем отражений.\")\n",
    "else:\n",
    "    print(\"Гипотеза не подтверждена: наличие металла не связано с высоким уровнем отражений.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гипотеза №6: Изображения с пластиком и стеклом часто имеют больше прозрачных областей.\n",
    "\n",
    "- Способы проверки:\n",
    "    - **Тест Манна-Уитни:** Сравнение распределений количества прозрачных областей на изображениях с пластиком и стеклом против других классов.\n",
    "    - **Коэффициент корреляции Спирмена:** Оценка монотонной зависимости между количеством прозрачных областей и классом изображения (пластик/стекло против остальных).\n",
    "    - **Тест Крускала-Уоллиса:** Сравнение медианных значений количества прозрачных областей между группами (пластик, стекло, другие классы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U test: U-statistic = 63373648.0, p-value = 2.0179651032763478e-82\n",
      "Spearman correlation: rho = -0.12222108103161104, p-value = 5.038550422304453e-83\n",
      "Kruskal-Wallis test: H-statistic = 369.849759985094, p-value = 4.876913498602153e-81\n",
      "Гипотеза подтверждается: пластик и стекло имеют больше прозрачных областей.\n"
     ]
    }
   ],
   "source": [
    "plastic_glass_classes = ['plastic', 'glass']\n",
    "transparency_data = {'plastic': [], 'glass': [], 'other': []}\n",
    "\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(path + \"/garbage-dataset/\", class_name)\n",
    "    image_paths = glob.glob(os.path.join(class_path, \"*.jpg\"))  # Предположим, что файлы изображений имеют расширение .jpg\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        image = cv2.imread(image_path)\n",
    "        transparency = calculate_transparency(image)\n",
    "\n",
    "        if class_name in plastic_glass_classes:\n",
    "            transparency_data['plastic'].append(transparency)\n",
    "            transparency_data['glass'].append(transparency)\n",
    "        else:\n",
    "            transparency_data['other'].append(transparency)\n",
    "\n",
    "# 1. Тест Манна-Уитни (для пластика/стекла против остальных)\n",
    "u_statistic, p_value_mw = mannwhitneyu(transparency_data['plastic'] + transparency_data['glass'], transparency_data['other'])\n",
    "print(f\"Mann-Whitney U test: U-statistic = {u_statistic}, p-value = {p_value_mw}\")\n",
    "\n",
    "# 2. Коэффициент корреляции Спирмена\n",
    "all_transparency = transparency_data['plastic'] + transparency_data['glass'] + transparency_data['other']\n",
    "labels = ['plastic_glass'] * (len(transparency_data['plastic']) + len(transparency_data['glass'])) + ['other'] * len(transparency_data['other'])\n",
    "\n",
    "spearman_corr, p_value_spearman = spearmanr(all_transparency, [1 if label == 'plastic_glass' else 0 for label in labels])\n",
    "print(f\"Spearman correlation: rho = {spearman_corr}, p-value = {p_value_spearman}\")\n",
    "\n",
    "# 3. Тест Крускала-Уоллиса\n",
    "kruskal_stat, p_value_kruskal = kruskal(transparency_data['plastic'], transparency_data['glass'], transparency_data['other'])\n",
    "print(f\"Kruskal-Wallis test: H-statistic = {kruskal_stat}, p-value = {p_value_kruskal}\")\n",
    "\n",
    "# Интерпретация гипотезы\n",
    "alpha = 0.05\n",
    "if p_value_mw < alpha and p_value_spearman < alpha and p_value_kruskal < alpha:\n",
    "    print(\"Гипотеза подтверждается: пластик и стекло имеют больше прозрачных областей.\")\n",
    "else:\n",
    "    print(\"Гипотеза не подтверждается: нет статистически значимых различий между классами.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
